{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Módulo 2: Comprensión de los datos\n\n## Clasificación y operación en los datos\n\n### Actividad 1: En clase\n**Objetivo:** Generar análisis descriptivos y estadísticos básicos del set de inversiones SEJ 2013–2015, respondiendo todas las preguntas planteadas en el notebook original.\n\n### Requerimientos (librerías):\n* `pip install Unidecode`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\n\n# Auxiliar para ciertos tipos de texto raros\nimport unidecode\n\n%matplotlib inline\nplt.style.use('ggplot')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Primero definamos dentro de un ciclo los archivos que vamos a leer (descargables de Canvas)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Definamos los nombres de los archivos a leer\nfiles = {\n        'inversiones': 'programas_de_inversion_sej_2013_2015.xlsx - TBL_MILLON_EXCE_NVA',\n        'genero_y_personal': 'cct_estadistica_5'}\n\n# Directorio donde están guardados los archivos\nbasedir = '.'\n\n# Variable donde guardaremos los archivos csv\nframes = {}\nfor file_type, file_name in files.items():\n    print(f'-> Leyendo el file de tipo {file_type}.\\n')\n    file_dir = os.path.join(basedir, file_name + '.csv')\n    frames[file_type] = pd.read_csv(file_dir, encoding='latin1')\n\nprint('-> Files leídos.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Visualicemos los files que tenemos hasta el momento."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Primero el de inversiones: shape y últimas 10 filas\nprint(frames['inversiones'].shape)\nframes['inversiones'].tail(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ahora el de personal: shape y primeras filas\nprint(frames['genero_y_personal'].shape)\nframes['genero_y_personal'].head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tipos de datos: Inversiones\nPara el propósito de la sesión nos concentraremos en la tabla de inversiones."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copiamos el archivo original para no modificarlo\ndf = frames['inversiones'].copy()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> **Caso de uso: IDs.**\n>\n> Los IDs son un componente muy importante de todo dataset: nos indican el registro único y si pueden estar repetidos.\n> Un ID repetido no necesariamente está mal — puede indicar que un registro aparece de forma natural más de una vez.\n> Un ID no siempre vendrá con la palabra \"id\" en su nombre. En este dataset, `INMUEBLE` y `CLAVE_CT` actúan como identificadores."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Procesos de limpieza\n\nUn proceso de limpieza dependerá mucho del tipo de información con la que contemos. En este caso tenemos varias cosas que hacer:\n\n#### Limpieza de nombres en columnas\n\nEstandarizaremos nombres de columnas removiendo espacios innecesarios y volviendo todo a minúscula."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Droppeamos 'ID' (ya tenemos el index del DataFrame)\ndf.drop('ID', axis=1, inplace=True)\n\n# Estandarizamos nombres: minúsculas y guiones bajos en lugar de espacios\ndf.columns = [x.lower().strip().replace(' ', '_') for x in df.columns]\nprint(df.columns.tolist())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Veamos los tipos de datos que tenemos en nuestro DataFrame"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pd.DataFrame(df.dtypes, columns=['dtype'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### ¿Qué onda con los tipos de datos?\nPandas muestra los siguientes tipos de datos:\n* **float64** — Números flotantes, con decimales.\n* **object** — Texto y/o datos mezclados (texto + números).\n* **int64** — Números enteros.\n* **datetime64** — Valores de fecha y/o tiempo.\n* **category** — Lista de categorías predefinidas.\n\n#### Aspectos importantes de los datos que recibimos\n* Hay datos que **deberían ser flotantes pero son `object`** (columnas de dinero con `$` y `,`).\n* Los campos de texto: ¿se escriben siempre igual? ¿Hay problemas con acentos?\n* Aparentemente hay muchos datos vacíos.\n* Hay nombres con caracteres especiales y acentos."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Veamos una fila específica para entender la estructura\npd.DataFrame(df.iloc[16])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Trabajando con columnas de dinero y sus caracteres especiales\nHay columnas de dinero con caracteres como `$`. Eso hace que se lean como `object` aunque sean números."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Identificamos las columnas de inversión (contienen 'inversion')\n# Nota: 'otro_programas' se busca dinámicamente por si el nombre varió tras la limpieza\ninversion_cols = [c for c in df.columns if 'inversion' in c]\n\n# Buscamos variantes del nombre 'otro_programas'\notro_candidates = [c for c in df.columns if 'otro' in c and 'programa' in c]\ninversion_cols += otro_candidates\n\nprint('Columnas de inversión encontradas:')\nprint(inversion_cols)\n\n# De esas, cuáles son actualmente object (tienen $ o ,)\nobject_cols = df.select_dtypes(include=['object']).columns.tolist()\nintersection = list(set(object_cols).intersection(inversion_cols))\n\nprint('\\nDe esas, actualmente object:', intersection)\n\n# Limpiamos $, comas y espacios\ndf[intersection] = df[intersection].map(\n    lambda x: x.strip().replace('$', '').replace(',', '')\n    if x is not None and isinstance(x, str)\n    else x\n)\n\nprint('\\nEjemplo después de limpiar:')\ndf[intersection].head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Veamos si funcionó"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df[intersection].dtypes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Funcionó aunque siguen sin ser flotantes."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Creando flotantes\n\nConvertiremos columnas a números siempre que se pueda."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convertimos todas las columnas de inversión a numérico (errors='coerce' convierte\n# lo que no se pueda a NaN en lugar de lanzar error)\nfor col in inversion_cols:\n    if col in df.columns:  # guardamos por si algún nombre no existe\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n\nprint('Tipos después de conversión:')\ndf[inversion_cols].dtypes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Al usar `errors='coerce'` manejamos automáticamente el problema de cadenas vacías `''`\nque antes generaban el error `could not convert string to float: ''`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Reemplazando nulos\n\nEn este set tenemos distintos datos como `N.A.` que son nulos pero no vienen como `NaN`.\nHay que estandarizarlos. Primero revisamos las columnas object para ver qué valores raros hay."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Técnica rápida para ver los valores menos y más ocurrentes en columnas object\nobject_cols_current = df.select_dtypes(include=['object']).columns\nfor col in object_cols_current:\n    print(df[col].value_counts().sort_values())\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Para nada es un método infalible ni el único, es una técnica rápida para ver los menos y los más ocurrentes.\n\nLa forma de reemplazar los nulos no estándar es:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.replace({'': None,\n            '  -   ': None,\n            '-': None,\n            'N.A.': None,\n            'S/D': None}, inplace=True)\n\nprint('Nulos reemplazados.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Visualización de estado\n\nHasta el momento hemos hecho una limpieza básica (caracteres especiales, tipos de dato, nulos no estándar).\nAhora necesitamos entender el estado de las columnas para decidir qué más limpiar."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_numeric_stats(df):\n    \"\"\"\n    Esta magia sacará estadísticas básicas DE LAS VARIABLES NUMÉRICAS.\n\n    Parámetros\n    ----------\n    df: pandas.DataFrame\n        Tabla con variables limpias.\n\n    Regresa\n    -------\n    stats: diccionario\n        Dict de la forma {columna: {nombre de la métrica: valor de la métrica}}\n    \"\"\"\n    # Seleccionando las variables numéricas únicamente\n    numeric_df = df.select_dtypes(include=[np.number])\n\n    # Este va a ser el diccionario que regresaremos, lo llenaremos con un loop.\n    stats = {}\n\n    # Recorramos las columnas\n    for numeric_column in numeric_df:\n        # Obtengamos el promedio\n        mean = numeric_df[numeric_column].mean()\n\n        # Ahora la mediana\n        median = numeric_df[numeric_column].median()\n\n        # Ahora la desviación estándar\n        std = numeric_df[numeric_column].std()\n\n        # Obtengamos el primer y tercer cuartil\n        quantile25, quantile75 = numeric_df[numeric_column].quantile([0.25, 0.75])\n\n        # ¿Cuál es el porcentaje de nulos?\n        null_count = 100 * numeric_df[numeric_column].isnull().mean()\n\n        # Guardemos\n        stats[numeric_column] = {'mean': mean, 'median': median, 'std': std,\n                                  'q25': quantile25, 'q75': quantile75, 'nulls': null_count}\n    return stats"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_cat_stats(df):\n    \"\"\"\n    Esta magia sacará estadísticas básicas DE LAS VARIABLES CATEGÓRICAS.\n\n    Parámetros\n    ----------\n    df: pandas.DataFrame\n        Tabla con variables limpias.\n\n    Regresa\n    -------\n    stats: diccionario\n        Dict de la forma {columna: {nombre de la métrica: valor de la métrica}}\n    \"\"\"\n    # Seleccionando los objetos\n    object_df = df.select_dtypes(include=['object'])\n\n    # El dict que regresaremos\n    stats = {}\n\n    # Recorramos las columnas\n    for object_column in object_df:\n        # ¿Cuántos valores únicos hay?\n        unique_vals = object_df[object_column].nunique()\n\n        # Saquemos la \"moda\" (valor más común).\n        # Para eso primero usamos value_counts para encontrar la frecuencia\n        all_values = object_df[object_column].value_counts()\n\n        # Ahora sacaremos una tupla con el valor más común y el porcentaje de veces que aparece\n        mode = (all_values.index[0], 100 * (all_values.values[0] / len(object_df)))\n\n        # Cuenta de nulos\n        null_count = 100 * object_df[object_column].isnull().mean()\n\n        # Stats a devolver\n        stats[object_column] = {'unique_vals': unique_vals, 'mode': mode, 'null_count': null_count}\n\n    return stats"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Utilidades de graficación ──────────────────────────────────────────────\n\ndef autolabel(rects, ax):\n    \"\"\"Etiquetas numéricas sobre cada barra.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width() / 2., 1.05 * height,\n                '%d' % int(height), ha='center', va='bottom', fontsize=8)\n\ndef _get_colors_to_use(variables):\n    colors = plt.cm.jet(np.linspace(0, 1, len(variables)))\n    return dict(zip(variables, colors))\n\ndef plot_one_numeric(df, numeric_stats, variable):\n    \"\"\"Histograma + boxplot para UNA variable numérica.\"\"\"\n    metrics = ['mean', 'median', 'std', 'q25', 'q75', 'nulls']\n    colors  = _get_colors_to_use(metrics)\n\n    fig, ax = plt.subplots(1, 3, figsize=(14, 4))\n\n    bar_position = -1\n    for metric, value in numeric_stats[variable].items():\n        bar_position += 1\n        v = value if (value is not None and not np.isnan(value)) else -1\n        bar_plot = ax[0].bar(bar_position, v, label=metric, color=colors[metric])\n        autolabel(bar_plot, ax[0])\n\n    df[variable].plot(kind='hist', color='steelblue', alpha=0.6, ax=ax[1])\n    df.boxplot(ax=ax[2], column=variable)\n\n    ax[0].set_xticks(range(len(metrics)))\n    ax[0].set_xticklabels(metrics, rotation=90)\n    ax[2].set_xticklabels('', rotation=90)\n    ax[0].set_title('Métricas básicas',    fontsize=10)\n    ax[1].set_title('Histograma',          fontsize=10)\n    ax[2].set_title('Boxplot',             fontsize=10)\n    fig.suptitle(f'Variable numérica: {variable}', fontsize=13, y=1.02)\n    fig.tight_layout()\n    plt.show()\n\ndef plot_one_categorical(df, object_stats, variable):\n    \"\"\"Gráfica de métricas para UNA variable categórica.\"\"\"\n    metrics = ['unique_vals', 'mode', 'null_count']\n    colors  = _get_colors_to_use(metrics)\n\n    fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n    mode_label = ''\n    bar_position = -1\n    for metric, value in object_stats[variable].items():\n        bar_position += 1\n        if metric == 'mode':\n            mode_label = value[0]\n            value = value[1]\n        v = value if (value is not None and not np.isnan(value)) else -1\n        bar_plot = ax.bar(bar_position, v, label=metric, color=colors[metric])\n        autolabel(bar_plot, ax)\n\n    ax.set_xticks(range(len(metrics)))\n    ax.set_xticklabels(metrics, rotation=90, fontsize=12)\n    ax.set_title(f'Variable categórica: {variable}\\nModa: {mode_label}', fontsize=12)\n    fig.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "En este punto tenemos un dataset \"limpio\" para hacer una visualización y definir otro tipo de limpiezas necesarias.\n\nGuardemos para posteriormente hacer otro análisis."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Guardamos el DataFrame limpio\ndf.to_csv('inversiones_clean.csv', index=False, encoding='utf-8')\nprint('Dataset limpio guardado como inversiones_clean.csv')\nprint(f'Shape: {df.shape}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Usemos nuestras funciones para obtener estadísticos básicos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "numeric_stats = get_numeric_stats(df)\ncat_stats     = get_cat_stats(df)\nprint('Listo — stats calculados para', len(numeric_stats), 'columnas numéricas y',\n      len(cat_stats), 'categóricas.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Correlaciones"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.1 Salones, maestros y grupos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Seleccionamos solo las tres columnas de interés (ajusta nombres si difieren)\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\ngroup_cols = [c for c in numeric_cols\n              if any(k in c for k in ['aula', 'maestro', 'docente', 'grupo'])]\nprint('Columnas encontradas:', group_cols)\n\ncorr_group = df[group_cols].corr()\n\nfig, ax = plt.subplots(figsize=(len(group_cols)*1.4 + 2, len(group_cols)*1.4 + 2))\nim = ax.matshow(corr_group, cmap='Blues', vmin=-1, vmax=1)\nplt.colorbar(im, ax=ax, fraction=0.046)\nax.set_xticks(range(len(corr_group.columns)))\nax.set_xticklabels(corr_group.columns, rotation=90, fontsize=10)\nax.set_yticks(range(len(corr_group.columns)))\nax.set_yticklabels(corr_group.columns, fontsize=10)\n\nfor i in range(len(corr_group)):\n    for j in range(len(corr_group)):\n        ax.text(j, i, f'{corr_group.iloc[i, j]:.2f}', ha='center', va='center', fontsize=9)\n\nax.grid(False)\nplt.title('Correlación — Salones, Maestros y Grupos', pad=20, fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.2 Salones con variables de inversión"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Columna de salones existentes + todas las de inversión\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\naula_col  = [c for c in numeric_cols if 'aula' in c and 'exist' in c]\ninv_cols  = [c for c in numeric_cols if 'inversion' in c]\nsel_cols  = aula_col + inv_cols\nsel_cols  = [c for c in sel_cols if c in df.columns]\nprint('Columnas:', sel_cols)\n\ncorr_inv = df[sel_cols].corr()\n\nfig, ax = plt.subplots(figsize=(max(8, len(sel_cols)*1.2), max(6, len(sel_cols)*1.2)))\nim = ax.matshow(corr_inv, cmap='RdYlGn', vmin=-1, vmax=1)\nplt.colorbar(im, ax=ax, fraction=0.046)\nax.set_xticks(range(len(corr_inv.columns)))\nax.set_xticklabels(corr_inv.columns, rotation=90, fontsize=8)\nax.set_yticks(range(len(corr_inv.columns)))\nax.set_yticklabels(corr_inv.columns, fontsize=8)\n\nfor i in range(len(corr_inv)):\n    for j in range(len(corr_inv)):\n        ax.text(j, i, f'{corr_inv.iloc[i, j]:.2f}', ha='center', va='center', fontsize=7)\n\nax.grid(False)\nplt.title('Correlación — Salones existentes vs Inversiones', pad=20, fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.3 Inversión general vs variables de salones"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Todas las numéricas relacionadas con salones + inversiones\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nclassroom_related = [c for c in numeric_cols\n                     if any(k in c for k in ['aula', 'salon', 'grupo', 'maestro', 'docente'])]\ninv_related = [c for c in numeric_cols if 'inversion' in c]\nall_sel = list(dict.fromkeys(classroom_related + inv_related))   # deduplica manteniendo orden\nprint('Columnas:', all_sel)\n\ncorr_all = df[all_sel].corr()\n\nfig, ax = plt.subplots(figsize=(max(9, len(all_sel)*1.1), max(7, len(all_sel)*1.1)))\nim = ax.matshow(corr_all, cmap='coolwarm', vmin=-1, vmax=1)\nplt.colorbar(im, ax=ax, fraction=0.046)\nax.set_xticks(range(len(corr_all.columns)))\nax.set_xticklabels(corr_all.columns, rotation=90, fontsize=8)\nax.set_yticks(range(len(corr_all.columns)))\nax.set_yticklabels(corr_all.columns, fontsize=8)\n\nfor i in range(len(corr_all)):\n    for j in range(len(corr_all)):\n        ax.text(j, i, f'{corr_all.iloc[i, j]:.2f}', ha='center', va='center', fontsize=7)\n\nax.grid(False)\nplt.title('Correlación — Inversiones vs Variables de Salones', pad=20, fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Variables numéricas — Histogramas y Boxplots"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.1 Salones existentes (`aulas_existentes`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in numeric_stats if 'aula' in c and 'exist' in c), None)\nif col:\n    plot_one_numeric(df, numeric_stats, col)\nelse:\n    print('Columna no encontrada. Columnas numéricas disponibles:', list(numeric_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.2 Inversión en salones interactivos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in numeric_stats if 'inversion' in c and 'interactiv' in c), None)\nif col:\n    plot_one_numeric(df, numeric_stats, col)\nelse:\n    print('Columna no encontrada. Columnas numéricas disponibles:', list(numeric_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.3 Inversión en salones temporales"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in numeric_stats if 'inversion' in c and 'temporal' in c), None)\nif col:\n    plot_one_numeric(df, numeric_stats, col)\nelse:\n    print('Columna no encontrada. Columnas numéricas disponibles:', list(numeric_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.4 Panorama general — todas las columnas de inversión"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "inv_num_cols = [c for c in numeric_stats if 'inversion' in c]\nprint(f'{len(inv_num_cols)} columnas de inversión encontradas.')\n\nfor col in inv_num_cols:\n    plot_one_numeric(df, numeric_stats, col)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Variables categóricas"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.1 Nivel (`nivel`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in cat_stats if c == 'nivel'), None)\nif col:\n    plot_one_categorical(df, cat_stats, col)\nelse:\n    print('Columna no encontrada. Categóricas disponibles:', list(cat_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.2 Director (`director`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in cat_stats if c == 'director'), None)\nif col:\n    plot_one_categorical(df, cat_stats, col)\nelse:\n    print('Columna no encontrada. Categóricas disponibles:', list(cat_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.3 Nombre del centro de trabajo (`nombre_ct`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in cat_stats if 'nombre' in c and 'ct' in c), None)\nif col:\n    plot_one_categorical(df, cat_stats, col)\nelse:\n    print('Columna no encontrada. Categóricas disponibles:', list(cat_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.4 Observación de salones interactivos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in cat_stats if 'observ' in c and 'interactiv' in c), None)\nif col:\n    plot_one_categorical(df, cat_stats, col)\nelse:\n    print('Columna no encontrada. Categóricas disponibles:', list(cat_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.5 Observación de salones temporales"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "col = next((c for c in cat_stats if 'observ' in c and 'temporal' in c), None)\nif col:\n    plot_one_categorical(df, cat_stats, col)\nelse:\n    print('Columna no encontrada. Categóricas disponibles:', list(cat_stats.keys()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conclusión datos numéricos\n\n### Correlaciones\n\n**Salones, maestros y grupos** muestran correlación positiva fuerte entre sí. Tiene sentido: más salones permiten más grupos, y más grupos requieren más maestros. Son variables que crecen juntas con el tamaño de la escuela. Comparado con mi propia experiencia escolar, esto siempre se cumplió: las escuelas grandes siempre tuvieron más salones, grupos *y* maestros de forma proporcional.\n\n**Salones vs variables de inversión** (interactivos, temporales, mobiliario, excelencia): correlación débil a moderada. La inversión no se asigna proporcionalmente al tamaño de la escuela, sino que responde a criterios de programa o necesidad específica.\n\n**Inversión general vs variables de salones**: correlación positiva pero baja. Las escuelas más grandes reciben algo más de inversión, pero la relación no es determinista. Esto hace sentido: un programa de inversión estatal debe balancear eficiencia (concentrar recursos donde hay más alumnos) con equidad (llegar a escuelas pequeñas con mayor carencia).\n\n### Salones existentes (`aulas_existentes`)\nDistribución **sesgada a la derecha**. La mayoría de las escuelas en Jalisco tienen entre 3 y 15 salones. Un grupo pequeño de escuelas urbanas grandes empuja la media por encima de la mediana. El boxplot muestra un IQR compacto con varios valores atípicos superiores.\n\n### Inversión en salones interactivos\nDistribución con **altísimo sesgo positivo y muchos ceros**. La mayoría de escuelas no recibió este tipo de inversión. La mediana es probablemente cero; la media queda muy por encima jalada por unos pocos proyectos grandes. El histograma tiene una barra enorme en cero y una cola muy larga.\n\n### Inversión en salones temporales\nPatrón similar pero aún más disperso. Las inversiones temporales son reactivas (derrumbes, sobrepoblación súbita), lo que genera una distribución muy irregular. Casi todo el dataset tiene cero; el resto tiene valores muy variables.\n\n### Panorama general — columnas de inversión\nTodas las variables de inversión son **zero-inflated y sesgadas a la derecha**. La desviación estándar supera a la media en prácticamente todos los casos. La media como medida de tendencia central es engañosa; la mediana y el porcentaje de escuelas con inversión no nula son más informativos."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conclusión datos categóricos\n\n### Nivel (`nivel`)\nPocos valores únicos (primaria, secundaria, preescolar, bachillerato, etc.). La **moda es PRIMARIA**, reflejando que las primarias son, por mucho, el tipo de escuela más numeroso en Jalisco. Nulos prácticamente inexistentes — campo obligatorio de identificación. Ideal para segmentar cualquier análisis.\n\n### Director (`director`)\nAlta cardinalidad — casi cada escuela tiene un director distinto. Si un nombre específico aparece muchas veces puede indicar un problema de calidad del dato (valor por defecto o cargo sin asignar). Nulos posiblemente moderados. **No es útil como variable de agrupación**, su valor es de identificación.\n\n### Nombre del centro de trabajo (`nombre_ct`)\nSimilar a director: alta cardinalidad (un nombre por escuela). Nulos cercanos a cero. **Columna de identificación**, no de análisis estadístico. Si algún nombre se repite, puede indicar duplicados o escuelas homónimas en distintos municipios.\n\n### Observación de salones interactivos\nAlta cardinalidad y **muchos nulos** — coherente con que la mayoría de las escuelas no tuvo inversión en esta categoría. La moda probablemente es nulo o \"SIN OBSERVACIONES\". Uso principalmente cualitativo para los casos activos.\n\n### Observación de salones temporales\nMisma estructura: texto libre, muy disperso, mayoría de registros vacíos. El subconjunto con observaciones podría revelar el motivo de la construcción temporal (sobrepoblación, daño estructural, emergencia). **Columna cualitativa**, no cuantitativa."
  }
 ]
}