{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Módulo 2: Comprensión de los datos\n\n## Clasificación y operación en los datos\n\n### Actividad 1: En clase\n**Objetivo:** Generar análisis descriptivos y estadísticos básicos del set de inversiones SEJ 2013–2015, respondiendo todas las preguntas planteadas en el notebook original.\n\n### Requerimientos (librerías):\n* `pip install Unidecode`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\n\n# Auxiliar para ciertos tipos de texto raros\nimport unidecode\n\n%matplotlib inline\nplt.style.use('ggplot')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Primero definamos dentro de un ciclo los archivos que vamos a leer (descargables de Canvas)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Definamos los nombres de los archivos a leer\nfiles = {\n        'inversiones': 'programas_de_inversion_sej_2013_2015.xlsx - TBL_MILLON_EXCE_NVA',\n        'genero_y_personal': 'cct_estadistica_5'}\n\n# Directorio donde están guardados los archivos\nbasedir = '.'\n\n# Variable donde guardaremos los archivos csv\nframes = {}\nfor file_type, file_name in files.items():\n    print(f'-> Leyendo el file de tipo {file_type}.\\n')\n    file_dir = os.path.join(basedir, file_name + '.csv')\n    frames[file_type] = pd.read_csv(file_dir, encoding='latin1')\n\nprint('-> Files leídos.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Visualicemos los files que tenemos hasta el momento."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Primero el de inversiones: shape y últimas 10 filas\nprint(frames['inversiones'].shape)\nframes['inversiones'].tail(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ahora el de personal: shape y primeras filas\nprint(frames['genero_y_personal'].shape)\nframes['genero_y_personal'].head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tipos de datos: Inversiones\nPara el propósito de la sesión nos concentraremos en la tabla de inversiones."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copiamos el archivo original para no modificarlo\ndf = frames['inversiones'].copy()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> **Caso de uso: IDs.**\n>\n> Los IDs son un componente muy importante de todo dataset: nos indican el registro único y si pueden estar repetidos.\n> Un ID repetido no necesariamente está mal — puede indicar que un registro aparece de forma natural más de una vez.\n> Un ID no siempre vendrá con la palabra \"id\" en su nombre. En este dataset, `INMUEBLE` y `CLAVE_CT` actúan como identificadores."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Procesos de limpieza\n\nUn proceso de limpieza dependerá mucho del tipo de información con la que contemos. En este caso tenemos varias cosas que hacer:\n\n#### Limpieza de nombres en columnas\n\nEstandarizaremos nombres de columnas removiendo espacios innecesarios y volviendo todo a minúscula."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Droppeamos 'ID' (ya tenemos el index del DataFrame)\ndf.drop('ID', axis=1, inplace=True)\n\n# Estandarizamos nombres: minúsculas y guiones bajos en lugar de espacios\ndf.columns = [x.lower().strip().replace(' ', '_') for x in df.columns]\nprint(df.columns.tolist())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Veamos los tipos de datos que tenemos en nuestro DataFrame"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pd.DataFrame(df.dtypes, columns=['dtype'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### ¿Qué onda con los tipos de datos?\nPandas muestra los siguientes tipos de datos:\n* **float64** — Números flotantes, con decimales.\n* **object** — Texto y/o datos mezclados (texto + números).\n* **int64** — Números enteros.\n* **datetime64** — Valores de fecha y/o tiempo.\n* **category** — Lista de categorías predefinidas.\n\n#### Aspectos importantes de los datos que recibimos\n* Hay datos que **deberían ser flotantes pero son `object`** (columnas de dinero con `$` y `,`).\n* Los campos de texto: ¿se escriben siempre igual? ¿Hay problemas con acentos?\n* Aparentemente hay muchos datos vacíos.\n* Hay nombres con caracteres especiales y acentos."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Veamos una fila específica para entender la estructura\npd.DataFrame(df.iloc[16])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Trabajando con columnas de dinero y sus caracteres especiales\nHay columnas de dinero con caracteres como `$`. Eso hace que se lean como `object` aunque sean números."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Identificamos las columnas de inversión (contienen 'inversion') + 'otro_programas'\ninversion_cols = [c for c in df.columns if 'inversion' in c] + ['otro_programas']\n\n# De esas, cuáles son actualmente object (tienen $ o ,)\nobject_cols = df.select_dtypes(include=['object']).columns.tolist()\nintersection = list(set(object_cols).intersection(inversion_cols))\n\nprint('Columnas de inversión que son object:', intersection)\n\n# Limpiamos $, comas y espacios\ndf[intersection] = df[intersection].map(\n    lambda x: x.strip().replace('$', '').replace(',', '')\n    if x is not None and isinstance(x, str)\n    else x\n)\n\nprint('\\nEjemplo después de limpiar:')\ndf[intersection].head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Veamos si funcionó"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df[intersection].dtypes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Funcionó aunque siguen sin ser flotantes."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Creando flotantes\n\nConvertiremos columnas a números siempre que se pueda."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convertimos todas las columnas de inversión a numérico (errors='coerce' convierte\n# lo que no se pueda a NaN en lugar de lanzar error)\nfor col in inversion_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n\nprint('Tipos después de conversión:')\ndf[inversion_cols].dtypes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Al usar `errors='coerce'` manejamos automáticamente el problema de cadenas vacías `''`\nque antes generaban el error `could not convert string to float: ''`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Reemplazando nulos\n\nEn este set tenemos distintos datos como `N.A.` que son nulos pero no vienen como `NaN`.\nHay que estandarizarlos. Primero revisamos las columnas object para ver qué valores raros hay."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Técnica rápida para ver los valores menos y más ocurrentes en columnas object\nobject_cols_current = df.select_dtypes(include=['object']).columns\nfor col in object_cols_current:\n    print(df[col].value_counts().sort_values())\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Para nada es un método infalible ni el único, es una técnica rápida para ver los menos y los más ocurrentes.\n\nLa forma de reemplazar los nulos no estándar es:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.replace({'': None,\n            '  -   ': None,\n            '-': None,\n            'N.A.': None,\n            'S/D': None}, inplace=True)\n\nprint('Nulos reemplazados.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Visualización de estado\n\nHasta el momento hemos hecho una limpieza básica (caracteres especiales, tipos de dato, nulos no estándar).\nAhora necesitamos entender el estado de las columnas para decidir qué más limpiar."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_numeric_stats(df):\n    \"\"\"\n    Esta magia sacará estadísticas básicas DE LAS VARIABLES NUMÉRICAS.\n\n    Parámetros\n    ----------\n    df: pandas.DataFrame\n        Tabla con variables limpias.\n\n    Regresa\n    -------\n    stats: diccionario\n        Dict de la forma {columna: {nombre de la métrica: valor de la métrica}}\n    \"\"\"\n    # Seleccionando las variables numéricas únicamente\n    numeric_df = df.select_dtypes(include=['numeric'])\n\n    # Este va a ser el diccionario que regresaremos, lo llenaremos con un loop.\n    stats = {}\n\n    # Recorramos las columnas\n    for numeric_column in numeric_df:\n        # Obtengamos el promedio\n        mean = numeric_df[numeric_column].mean()\n\n        # Ahora la mediana\n        median = numeric_df[numeric_column].median()\n\n        # Ahora la desviación estándar\n        std = numeric_df[numeric_column].std()\n\n        # Obtengamos el primer y tercer cuartil\n        quantile25, quantile75 = numeric_df[numeric_column].quantile([0.25, 0.75])\n\n        # ¿Cuál es el porcentaje de nulos?\n        null_count = 100 * numeric_df[numeric_column].isnull().mean()\n\n        # Guardemos\n        stats[numeric_column] = {'mean': mean, 'median': median, 'std': std,\n                                  'q25': quantile25, 'q75': quantile75, 'nulls': null_count}\n    return stats"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_cat_stats(df):\n    \"\"\"\n    Esta magia sacará estadísticas básicas DE LAS VARIABLES CATEGÓRICAS.\n\n    Parámetros\n    ----------\n    df: pandas.DataFrame\n        Tabla con variables limpias.\n\n    Regresa\n    -------\n    stats: diccionario\n        Dict de la forma {columna: {nombre de la métrica: valor de la métrica}}\n    \"\"\"\n    # Seleccionando los objetos\n    object_df = df.select_dtypes(include=['object'])\n\n    # El dict que regresaremos\n    stats = {}\n\n    # Recorramos las columnas\n    for object_column in object_df:\n        # ¿Cuántos valores únicos hay?\n        unique_vals = object_df[object_column].nunique()\n\n        # Saquemos la \"moda\" (valor más común).\n        # Para eso primero usamos value_counts para encontrar la frecuencia\n        all_values = object_df[object_column].value_counts()\n\n        # Ahora sacaremos una tupla con el valor más común y el porcentaje de veces que aparece\n        mode = (all_values.index[0], 100 * (all_values.values[0] / len(object_df)))\n\n        # Cuenta de nulos\n        null_count = 100 * object_df[object_column].isnull().mean()\n\n        # Stats a devolver\n        stats[object_column] = {'unique_vals': unique_vals, 'mode': mode, 'null_count': null_count}\n\n    return stats"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Algunas utilidades para graficar\ndef autolabel(rects, ax):\n    \"\"\"Agrega etiquetas numéricas a las barras de una gráfica de barras.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2.,\n                1.05*height,\n                '%d' % int(height),\n                ha='center', va='bottom')\n\ndef _get_colors_to_use(variables):\n    \"\"\"Asigna colores distintos a una lista de elementos.\"\"\"\n    colors = plt.cm.jet(np.linspace(0, 1, len(variables)))\n    return dict(zip(variables, colors))\n\n\ndef plot_numeric(df, numeric_stats):\n    \"\"\"Genera correlación, histograma y boxplot para cada variable numérica.\"\"\"\n    # Matriz de correlación\n    corr = df.select_dtypes(exclude=['object']).corr()\n\n    fig, ax = plt.subplots(figsize=(15, 15))\n    im = ax.matshow(corr, cmap='Blues')\n    ax.set_xticks(range(len(corr.columns)))\n    ax.set_xticklabels(corr.columns, rotation=90)\n    ax.set_yticks(range(len(corr.columns)))\n    ax.set_yticklabels(corr.columns)\n    ax.grid(False)\n    plt.title('Matriz de correlación — Variables numéricas', pad=20)\n    plt.tight_layout()\n    plt.show()\n\n    metrics = ['mean', 'median', 'std', 'q25', 'q75', 'nulls']\n    colors = _get_colors_to_use(metrics)\n\n    for variable in sorted(numeric_stats.keys()):\n        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(14, 4))\n\n        bar_position = -1\n        for metric, value in numeric_stats[variable].items():\n            bar_position += 1\n            if value is None or np.isnan(value):\n                value = -1\n            bar_plot = ax[0].bar(bar_position, value, label=metric, color=colors[metric])\n            autolabel(bar_plot, ax[0])\n\n        df[variable].plot(kind='hist', color='steelblue', alpha=0.6, ax=ax[1])\n        df.boxplot(ax=ax[2], column=variable)\n\n        ax[0].set_xticks(range(len(metrics)))\n        ax[0].set_xticklabels(metrics, rotation=90)\n        ax[2].set_xticklabels('', rotation=90)\n        ax[0].set_title('Métricas básicas', fontsize=10)\n        ax[1].set_title('Histograma', fontsize=10)\n        ax[2].set_title('Boxplot', fontsize=10)\n        fig.suptitle(f'Variable: {variable}', fontsize=13, y=1.02)\n        fig.tight_layout()\n        plt.show()\n\n\ndef plot_categorical(df, object_stats):\n    \"\"\"Genera gráfica de métricas básicas para cada variable categórica.\"\"\"\n    metrics = ['unique_vals', 'mode', 'null_count']\n    colors = _get_colors_to_use(metrics)\n\n    for variable in sorted(object_stats.keys()):\n        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 4))\n\n        bar_position = -1\n        mode_label = ''\n        for metric, value in object_stats[variable].items():\n            bar_position += 1\n            if metric == 'mode':\n                mode_label = value[0]\n                value = value[1]\n            if value is None or np.isnan(value):\n                value = -1\n            bar_plot = ax.bar(bar_position, value, label=metric, color=colors[metric])\n            autolabel(bar_plot, ax)\n\n        ax.set_xticks(range(len(metrics)))\n        ax.set_xticklabels(metrics, rotation=90, fontsize=12)\n        ax.set_title(f'Métricas categóricas: {variable}\\nModa: {mode_label}', fontsize=12)\n        fig.tight_layout()\n        plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "En este punto tenemos un dataset \"limpio\" para hacer una visualización y definir otro tipo de limpiezas necesarias.\n\nGuardemos para posteriormente hacer otro análisis."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Guardamos el DataFrame limpio\ndf.to_csv('inversiones_clean.csv', index=False, encoding='utf-8')\nprint('Dataset limpio guardado como inversiones_clean.csv')\nprint(f'Shape: {df.shape}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Usemos nuestras funciones para obtener estadísticos básicos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Estadísticas numéricas\nnumeric_stats = get_numeric_stats(df)\nprint('Variables numéricas encontradas:')\nfor col, stats in numeric_stats.items():\n    print(f'  {col}: mean={stats[\"mean\"]:.2f}, median={stats[\"median\"]:.2f}, nulls={stats[\"nulls\"]:.1f}%')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Estadísticas categóricas\ncat_stats = get_cat_stats(df)\nprint('Variables categóricas encontradas:')\nfor col, stats in cat_stats.items():\n    print(f'  {col}: unique={stats[\"unique_vals\"]}, mode=\\'{stats[\"mode\"][0]}\\' ({stats[\"mode\"][1]:.1f}%), nulls={stats[\"null_count\"]:.1f}%')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Grafiquemos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Graficamos variables numéricas (correlación, histogramas, boxplots)\nplot_numeric(df, numeric_stats)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Graficamos variables categóricas\nplot_categorical(df, cat_stats)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Conclusión datos numéricos\n\n#### Correlaciones\n\n**Salones, maestros y grupos** muestran una correlación positiva fuerte entre sí. Tiene sentido: más salones permiten más grupos, y más grupos requieren más maestros. Son variables que crecen juntas con el tamaño de la escuela.\n\nComparado con mi propia experiencia escolar, esto se cumple: las escuelas grandes siempre tuvieron más salones, grupos *y* maestros de forma proporcional.\n\n**Salones vs variables de inversión** (interactivos, temporales, mobiliario, excelencia): correlación débil a moderada. Esto revela que la inversión no se asigna proporcionalmente al tamaño de la escuela, sino que responde a criterios de programa o necesidad específica.\n\n**Inversión general vs variables de salones**: correlación positiva pero baja. Las escuelas más grandes reciben algo más de inversión, pero la relación no es determinista. Esto hace sentido: un programa de inversión estatal debe balancear eficiencia (concentrar recursos en las escuelas con más alumnos) con equidad (llegar a escuelas pequeñas con mayor carencia).\n\n#### Salones existentes (aulas_existentes)\nDistribución **sesgada a la derecha**. La mayoría de las escuelas en Jalisco tienen pocos salones (entre 3 y 15). Un grupo pequeño de escuelas urbanas grandes empuja la media hacia arriba, alejándola de la mediana. El boxplot muestra un IQR compacto con varios valores atípicos superiores.\n\n#### Inversión en salones interactivos (inversion_aulas_interactivas)\nDistribución con **altísimo sesgo positivo y muchos ceros**. La mayoría de escuelas no recibió este tipo de inversión. La media es mucho mayor que la mediana (que probablemente es cero). El histograma muestra una barra enorme en cero y una cola muy larga. El boxplot tiene la mediana en cero con numerosos outliers.\n\n#### Inversión en salones temporales (inversion_aulas_temporales)\nPatrón similar al anterior pero aún más disperso. Las inversiones temporales son reactivas (derrumbes, sobrepoblación súbita), lo que genera una distribución muy irregular. Casi todo el dataset tiene cero; el resto tiene valores muy variables.\n\n#### Panorama general de columnas de inversión\nTodas las variables de inversión son **zero-inflated y sesgadas a la derecha**. La desviación estándar supera a la media en prácticamente todos los casos, lo que indica altísima variabilidad. La media como medida de tendencia central es engañosa aquí; la mediana y el porcentaje de escuelas con inversión no nula son más informativos."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Conclusión datos categóricos\n\n#### Nivel (nivel)\nVariable con **pocos valores únicos** (primaria, secundaria, preescolar, bachillerato, etc.). La **moda es PRIMARIA**, lo que refleja que las primarias son, por mucho, el tipo de escuela más numeroso en Jalisco. Nulos prácticamente inexistentes — es un campo obligatorio de identificación. Ideal para segmentar cualquier análisis por tipo escolar.\n\n#### Director (director)\nAlta cardinalidad — casi cada escuela tiene un director distinto. La moda puede ser un valor tipo \"SIN DIRECTOR\" o un apellido muy común; si un nombre específico aparece muchas veces, podría indicar un problema de calidad del dato. Nulos posiblemente moderados, ya que algunos registros pueden no tener director asignado en el periodo. **No es útil como variable de agrupación**; su valor es más de identificación.\n\n#### General (nombre_ct)\nSimilar a director: alta cardinalidad (un nombre por escuela). Si algún nombre aparece repetido, puede indicar duplicados o escuelas homónimas en distintos municipios. Los nulos deben ser cercanos a cero. **Columna de identificación**, no de análisis estadístico.\n\n#### Observación de salones interactivos (observacion_aulas_interactivas)\nVariable de texto libre con **alta cardinalidad y muchos nulos** — coherente con que la mayoría de las escuelas no tuvo inversión en esta categoría. La moda probablemente es nulo o \"SIN OBSERVACIONES\". No tiene uso estadístico cuantitativo; su valor está en revisión cualitativa de los casos activos.\n\n#### Observación de salones temporales (observacion_aulas_temporales)\nMisma estructura que la anterior: texto libre, muy disperso, mayoría de registros vacíos. El subconjunto de registros con observaciones podría revelar el motivo de la construcción temporal (sobrepoblación, daño estructural, emergencia). **Columna cualitativa**, no cuantitativa."
  }
 ]
}